{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Machine Learning inside of Pipline\n",
    "[Recently, we presented](https://www.quantopian.com/posts/machine-learning-on-quantopian) how to load alpha signals into a research notebook, preprocess them, and then train a Machine Learning classifier to predict future returns. This was done in a static fashion, meaning we loaded data once over a fixed period of time (using the `run_pipeline()` command), split into test and train, and predicted inside of the research notebook.\n",
    "\n",
    "This leaves open the question of how to move this workflow to a trading algorithm, where `run_pipeline()` is not available. Here we show how you can move your ML steps into a pipeline `CustomFactor` where the classifier gets retrained periodically on the most recent data and predicts returns. This is still not moving things into a trading algorithm, but it gets us one step closer.\n",
    "\n",
    "If you haven't yet, definitely read the notebook on the [static workflow](https://www.quantopian.com/posts/machine-learning-on-quantopian) first. We will be reusing the same concepts and code but not re-explain the logic of preprocessing the data.\n",
    "\n",
    "### Disclaimer\n",
    "This workflow is still a bit rough around the edges. We are working on improving it and adding better educational materials. This serves as a sneak-peek for the curious and adventurous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from quantopian.research import run_pipeline\n",
    "from quantopian.pipeline import Pipeline\n",
    "from quantopian.pipeline.factors import Latest\n",
    "from quantopian.pipeline.data.builtin import USEquityPricing\n",
    "from quantopian.pipeline.data import morningstar\n",
    "from quantopian.pipeline.factors import CustomFactor, SimpleMovingAverage, AverageDollarVolume, Returns, RSI\n",
    "from quantopian.pipeline.classifiers.morningstar import Sector\n",
    "from quantopian.pipeline.filters import Q500US, Q1500US, QTradableStocksUS\n",
    "from quantopian.pipeline.data.quandl import fred_usdontd156n as libor\n",
    "from quantopian.pipeline.data.zacks import EarningsSurprises\n",
    "\n",
    "import talib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import time\n",
    "\n",
    "import alphalens as al\n",
    "import pyfolio as pf\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model, decomposition, ensemble, preprocessing, isotonic, metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Definition of some commonly used factors\n",
    "The factors below are a small collection of commonly used alphas that were coded by Gil Wassermann. I will post a separate Notebook with the full collection and more descriptions of them. Ultimately we will put these into a library you can just import to avoid the wall of text. If you want to understand more about pipeline, read the [tutorial](https://www.quantopian.com/tutorials/pipeline)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "bs = morningstar.balance_sheet\n",
    "cfs = morningstar.cash_flow_statement\n",
    "is_ = morningstar.income_statement\n",
    "or_ = morningstar.operation_ratios\n",
    "er = morningstar.earnings_report\n",
    "v = morningstar.valuation\n",
    "vr = morningstar.valuation_ratios\n",
    "\n",
    "\n",
    "def make_factors():\n",
    "    def Asset_Growth_3M():\n",
    "        return Returns(inputs=[bs.total_assets], window_length=63)\n",
    "\n",
    "    def Asset_To_Equity_Ratio():\n",
    "        return bs.total_assets.latest / bs.common_stock_equity.latest\n",
    "\n",
    "    def Capex_To_Cashflows():\n",
    "        return (cfs.capital_expenditure.latest * 4.) / \\\n",
    "            (cfs.free_cash_flow.latest * 4.)\n",
    "        \n",
    "    def EBITDA_Yield():\n",
    "        return (is_.ebitda.latest * 4.) / \\\n",
    "            USEquityPricing.close.latest        \n",
    "\n",
    "    def EBIT_To_Assets():\n",
    "        return (is_.ebit.latest * 4.) / \\\n",
    "            bs.total_assets.latest\n",
    "        \n",
    "    def Earnings_Quality():\n",
    "        return morningstar.cash_flow_statement.operating_cash_flow.latest / \\\n",
    "               EarningsSurprises.eps_act.latest\n",
    "        \n",
    "    def Return_On_Total_Invest_Capital():\n",
    "        return or_.roic.latest\n",
    "    \n",
    "    class Mean_Reversion_1M(CustomFactor):\n",
    "        inputs = [Returns(window_length=21)]\n",
    "        window_length = 252\n",
    "\n",
    "        def compute(self, today, assets, out, monthly_rets):\n",
    "            out[:] = (monthly_rets[-1] - np.nanmean(monthly_rets, axis=0)) / \\\n",
    "                np.nanstd(monthly_rets, axis=0)\n",
    "                \n",
    "    class MACD_Signal_10d(CustomFactor):\n",
    "        inputs = [USEquityPricing.close]\n",
    "        window_length = 60\n",
    "\n",
    "        def compute(self, today, assets, out, close):\n",
    "\n",
    "            sig_lines = []\n",
    "\n",
    "            for col in close.T:\n",
    "                # get signal line only\n",
    "                try:\n",
    "                    _, signal_line, _ = talib.MACD(col, fastperiod=12,\n",
    "                                                   slowperiod=26, signalperiod=10)\n",
    "                    sig_lines.append(signal_line[-1])\n",
    "                # if error calculating, return NaN\n",
    "                except:\n",
    "                    sig_lines.append(np.nan)\n",
    "            out[:] = sig_lines \n",
    "            \n",
    "    class Moneyflow_Volume_5d(CustomFactor):\n",
    "        inputs = [USEquityPricing.close, USEquityPricing.volume]\n",
    "        window_length = 5\n",
    "\n",
    "        def compute(self, today, assets, out, close, volume):\n",
    "\n",
    "            mfvs = []\n",
    "\n",
    "            for col_c, col_v in zip(close.T, volume.T):\n",
    "\n",
    "                # denominator\n",
    "                denominator = np.dot(col_c, col_v)\n",
    "\n",
    "                # numerator\n",
    "                numerator = 0.\n",
    "                for n, price in enumerate(col_c.tolist()):\n",
    "                    if price > col_c[n - 1]:\n",
    "                        numerator += price * col_v[n]\n",
    "                    else:\n",
    "                        numerator -= price * col_v[n]\n",
    "\n",
    "                mfvs.append(numerator / denominator)\n",
    "            out[:] = mfvs  \n",
    "            \n",
    "           \n",
    "    def Net_Income_Margin():\n",
    "        return or_.net_margin.latest           \n",
    "\n",
    "    def Operating_Cashflows_To_Assets():\n",
    "        return (cfs.operating_cash_flow.latest * 4.) / \\\n",
    "            bs.total_assets.latest\n",
    "\n",
    "    def Price_Momentum_3M():\n",
    "        return Returns(window_length=63)\n",
    "    \n",
    "    class Price_Oscillator(CustomFactor):\n",
    "        inputs = [USEquityPricing.close]\n",
    "        window_length = 252\n",
    "\n",
    "        def compute(self, today, assets, out, close):\n",
    "            four_week_period = close[-20:]\n",
    "            out[:] = (np.nanmean(four_week_period, axis=0) /\n",
    "                      np.nanmean(close, axis=0)) - 1.\n",
    "    \n",
    "    def Returns_39W():\n",
    "        return Returns(window_length=215)\n",
    "    \n",
    "    class Trendline(CustomFactor):\n",
    "        inputs = [USEquityPricing.close]\n",
    "        window_length = 252\n",
    "\n",
    "        # using MLE for speed\n",
    "        def compute(self, today, assets, out, close):\n",
    "\n",
    "            # prepare X matrix (x_is - x_bar)\n",
    "            X = range(self.window_length)\n",
    "            X_bar = np.nanmean(X)\n",
    "            X_vector = X - X_bar\n",
    "            X_matrix = np.tile(X_vector, (len(close.T), 1)).T\n",
    "\n",
    "            # prepare Y matrix (y_is - y_bar)\n",
    "            Y_bar = np.nanmean(close, axis=0)\n",
    "            Y_bars = np.tile(Y_bar, (self.window_length, 1))\n",
    "            Y_matrix = close - Y_bars\n",
    "\n",
    "            # prepare variance of X\n",
    "            X_var = np.nanvar(X)\n",
    "\n",
    "            # multiply X matrix an Y matrix and sum (dot product)\n",
    "            # then divide by variance of X\n",
    "            # this gives the MLE of Beta\n",
    "            out[:] = (np.sum((X_matrix * Y_matrix), axis=0) / X_var) / \\\n",
    "                (self.window_length)\n",
    "        \n",
    "    class Vol_3M(CustomFactor):\n",
    "        inputs = [Returns(window_length=2)]\n",
    "        window_length = 63\n",
    "\n",
    "        def compute(self, today, assets, out, rets):\n",
    "            out[:] = np.nanstd(rets, axis=0)\n",
    "            \n",
    "    def Working_Capital_To_Assets():\n",
    "        return bs.working_capital.latest / bs.total_assets.latest\n",
    "        \n",
    "    all_factors = {\n",
    "        'Asset Growth 3M': Asset_Growth_3M,\n",
    "        'Asset to Equity Ratio': Asset_To_Equity_Ratio,\n",
    "        'Capex to Cashflows': Capex_To_Cashflows,\n",
    "        'EBIT to Assets': EBIT_To_Assets,\n",
    "        'EBITDA Yield': EBITDA_Yield,        \n",
    "        'Earnings Quality': Earnings_Quality,\n",
    "        'MACD Signal Line': MACD_Signal_10d,\n",
    "        'Mean Reversion 1M': Mean_Reversion_1M,\n",
    "        'Moneyflow Volume 5D': Moneyflow_Volume_5d,\n",
    "        'Net Income Margin': Net_Income_Margin,        \n",
    "        'Operating Cashflows to Assets': Operating_Cashflows_To_Assets,\n",
    "        'Price Momentum 3M': Price_Momentum_3M,\n",
    "        'Price Oscillator': Price_Oscillator,\n",
    "        'Return on Invest Capital': Return_On_Total_Invest_Capital,\n",
    "        '39 Week Returns': Returns_39W,\n",
    "        'Trendline': Trendline,\n",
    "        'Vol 3M': Vol_3M,\n",
    "        'Working Capital to Assets': Working_Capital_To_Assets,        \n",
    "    }        \n",
    "    \n",
    "    return all_factors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<a></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Define universe and select factors to use\n",
    "We will screen our universe using the new [Q1500US](https://www.quantopian.com/posts/the-q500us-and-q1500us) and hand-pick a few alphas from the list above. We encourage you to play around with the factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "universe = QTradableStocksUS()\n",
    "\n",
    "factors = make_factors()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Define helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "n_fwd_days = 5 # number of days to compute returns over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def shift_mask_data(X, Y, upper_percentile=70, lower_percentile=30, n_fwd_days=1):\n",
    "    # Shift X to match factors at t to returns at t+n_fwd_days (we want to predict future returns after all)\n",
    "    shifted_X = np.roll(X, n_fwd_days+1, axis=0)\n",
    "    \n",
    "    # Slice off rolled elements\n",
    "    X = shifted_X[n_fwd_days+1:]\n",
    "    Y = Y[n_fwd_days+1:]\n",
    "    \n",
    "    n_time, n_stocks, n_factors = X.shape\n",
    "    \n",
    "    # Look for biggest up and down movers\n",
    "    upper = np.nanpercentile(Y, upper_percentile, axis=1)[:, np.newaxis]\n",
    "    lower = np.nanpercentile(Y, lower_percentile, axis=1)[:, np.newaxis]\n",
    "  \n",
    "    upper_mask = (Y >= upper)\n",
    "    lower_mask = (Y <= lower)\n",
    "    \n",
    "    mask = upper_mask | lower_mask # This also drops nans\n",
    "    mask = mask.flatten()\n",
    "    \n",
    "    # Only try to predict whether a stock moved up/down relative to other stocks\n",
    "    Y_binary = np.zeros(n_time * n_stocks)\n",
    "    Y_binary[upper_mask.flatten()] = 1\n",
    "    Y_binary[lower_mask.flatten()] = -1\n",
    "    \n",
    "    # Flatten X\n",
    "    X = X.reshape((n_time * n_stocks, n_factors))\n",
    "\n",
    "    # Drop stocks that did not move much (i.e. are in the 30th to 70th percentile)\n",
    "    X = X[mask]\n",
    "    Y_binary = Y_binary[mask]\n",
    "    \n",
    "    return X, Y_binary\n",
    "\n",
    "def get_last_values(input_data):\n",
    "    last_values = []\n",
    "    for dataset in input_data:\n",
    "        last_values.append(dataset[-1])\n",
    "    return np.vstack(last_values).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Define the Machine Learning Pipeline Factor\n",
    "Where before we called `run_pipeline()` to get our data and then train a ML model on the `DataFrame` we received, we now move this step into a Pipeline Factor as well. The steps taken are the same, first we make the factor values match up with the future returns, we binarize the returns, and then impute and scale. Note that we retrain the model only weekly but certainly that's a choice you have to make.\n",
    "\n",
    "The same factor then also does prediction. For that we call the `.predict_proba()` method which returns a probability of the stock going up. Ultimately, this output will feed into the next stage: portfolio construction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class ML(CustomFactor):\n",
    "    init = False\n",
    "\n",
    "    def compute(self, today, assets, out, returns, *inputs):\n",
    "        # inputs is a list of factors, for example, assume we have 2 alpha signals, 3 stocks,\n",
    "        # and a lookback of 2 days. Each element in the inputs list will be data of\n",
    "        # one signal, so len(inputs) == 2. Then each element will contain a 2-D array\n",
    "        # of shape [time x stocks]. For example:\n",
    "        # inputs[0]:\n",
    "        # [[1, 3, 2], # factor 1 rankings of day t-1 for 3 stocks  \n",
    "        #  [3, 2, 1]] # factor 1 rankings of day t for 3 stocks\n",
    "        # inputs[1]:\n",
    "        # [[2, 3, 1], # factor 2 rankings of day t-1 for 3 stocks\n",
    "        #  [1, 2, 3]] # factor 2 rankings of day t for 3 stocks\n",
    "        \n",
    "        if (not self.init) or (today.weekday() == 0): # Monday\n",
    "            # Instantiate sklearn objects\n",
    "            self.imputer = preprocessing.Imputer()\n",
    "            self.scaler = preprocessing.MinMaxScaler()\n",
    "            self.clf = ensemble.AdaBoostClassifier(n_estimators=100)\n",
    "            \n",
    "            # Stack factor rankings\n",
    "            X = np.dstack(inputs) # (time, stocks, factors)\n",
    "            Y = returns # (time, stocks)\n",
    "        \n",
    "            # Shift data to match with future returns and binarize \n",
    "            # returns based on their \n",
    "            X, Y = shift_mask_data(X, Y, n_fwd_days=n_fwd_days)\n",
    "            \n",
    "            X = self.imputer.fit_transform(X)            \n",
    "            X = self.scaler.fit_transform(X)\n",
    "            \n",
    "            # Fit the classifier\n",
    "            self.clf.fit(X, Y)\n",
    "            \n",
    "            self.init = True\n",
    "\n",
    "        # Predict\n",
    "        # Get most recent factor values (inputs always has the full history)\n",
    "        last_factor_values = get_last_values(inputs)\n",
    "        last_factor_values = self.imputer.transform(last_factor_values)\n",
    "        last_factor_values = self.scaler.transform(last_factor_values)\n",
    "\n",
    "        # Predict the probability for each stock going up \n",
    "        # (column 2 of the output of .predict_proba()) and\n",
    "        # return it via assignment to out.\n",
    "        out[:] = self.clf.predict_proba(last_factor_values)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "def make_ml_pipeline(factors, universe, window_length=30, n_fwd_days=5):\n",
    "    factors_pipe = OrderedDict()\n",
    "    # Create returns over last n days.\n",
    "    factors_pipe['Returns'] = Returns(inputs=[USEquityPricing.open],\n",
    "                                      mask=universe, window_length=n_fwd_days)\n",
    "    # Instantiate ranked factors\n",
    "    for name, f in factors.iteritems():\n",
    "        factors_pipe[name] = f().rank(mask=universe)\n",
    "        \n",
    "    # Create our ML pipeline factor. The window_length will control how much\n",
    "    # lookback the passed in data will have.\n",
    "    factors_pipe['ML'] = ML(inputs=factors_pipe.values(), \n",
    "                            window_length=window_length + 1, \n",
    "                            mask=universe)\n",
    "    \n",
    "    pipe = Pipeline(screen=universe, columns=factors_pipe)\n",
    "    \n",
    "    return pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "ml_pipe = make_ml_pipeline(factors, universe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "start_timer = time()\n",
    "start = pd.Timestamp(\"2015-01-01\") # Can't choose a much longer time-period or we run out of RAM\n",
    "end = pd.Timestamp(\"2016-03-01\")\n",
    "\n",
    "results = run_pipeline(ml_pipe, start_date=start, end_date=end)\n",
    "\n",
    "end_timer = time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print \"Time to run pipeline %.2f secs\" % (end_timer - start_timer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "What happened here?\n",
    "\n",
    "Our complete pipeline was run every day with the current data (look-ahead bias free). Every Monday we preprocessed the data and trained a classifier. We then used that classifier for predictions on subsequent days.\n",
    "\n",
    "The 'ML' column will contain for each day, the predicted probabilities of each stock to go up, relative to the other ones in the universe. From here we could create a portfolio inside of an algorithm and trade into it. We will show this step in a future post. Lets examine what the output looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "results['ML'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "results['ML'].tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Analyzing our mega-alpha with pipeline\n",
    "It's important to realize that our predictions are just another alpha signal (one that is hopefully more predictive than each individual signal in isolation). Because of that, we can analyze just like any other alpha signal with [AlphaLens](https://www.quantopian.com/posts/alphalens-a-new-tool-for-analyzing-alpha-factors).\n",
    "\n",
    "First, we need to get the pricing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "assets = results.index.levels[1]\n",
    "pricing = get_pricing(assets, start, end + pd.Timedelta(days=30), fields=\"open_price\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Then call `create_factor_tear_sheet()` with our factor and the pricing data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "factor_data = al.utils.get_clean_factor_and_forward_returns(results['ML'], pricing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "al.tears.create_full_tear_sheet(factor_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We see a pretty nice separation of the stocks where low probabilities (low quantiles) are associated with negative future returns and high probabilities (high quantiles) are associated with positive future returns. This is completely look-ahead bias free as we never used any future data to train the model.\n",
    "\n",
    "Note that I picked a time range that worked pretty well. The tear sheet does not look as good in the more recent past.\n",
    "\n",
    "## Credits\n",
    "By Thomas Wiecki &amp; James Christopher.\n",
    "\n",
    "Thanks to Scott Sanderson for useful discussions, building pipeline, and for making it more memory efficient. Thanks to Jamie McCorriston and Max Margenot for feedback on an earlier draft."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
