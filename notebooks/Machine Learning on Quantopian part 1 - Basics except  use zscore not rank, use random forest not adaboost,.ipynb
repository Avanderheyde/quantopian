{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the sourse of code go from https://www.quantopian.com/posts/machine-learning-on-quantopian\n",
    "# import libraries\n",
    "from quantopian.research import run_pipeline\n",
    "from quantopian.pipeline import Pipeline\n",
    "from quantopian.pipeline.factors import Latest\n",
    "from quantopian.pipeline.data.builtin import USEquityPricing\n",
    "from quantopian.pipeline.data import morningstar\n",
    "from quantopian.pipeline.factors import CustomFactor, SimpleMovingAverage, AverageDollarVolume, Returns, RSI\n",
    "from quantopian.pipeline.classifiers.morningstar import Sector\n",
    "from quantopian.pipeline.filters import Q500US, Q1500US\n",
    "from quantopian.pipeline.data.quandl import fred_usdontd156n as libor\n",
    "from quantopian.pipeline.data.zacks import EarningsSurprises\n",
    "from quantopian.pipeline.classifiers.morningstar import Sector\n",
    "\n",
    "import talib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import time\n",
    "\n",
    "import alphalens as al\n",
    "import pyfolio as pf\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import linear_model, decomposition, ensemble, preprocessing, isotonic, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#definition of factors\n",
    "bs = morningstar.balance_sheet\n",
    "cfs = morningstar.cash_flow_statement\n",
    "is_ = morningstar.income_statement\n",
    "or_ = morningstar.operation_ratios\n",
    "er = morningstar.earnings_report\n",
    "v = morningstar.valuation\n",
    "vr = morningstar.valuation_ratios\n",
    "\n",
    "\n",
    "def make_factors():\n",
    "    def Asset_Growth_3M():\n",
    "        return Returns(inputs=[bs.total_assets], window_length=63)\n",
    "\n",
    "    def Asset_To_Equity_Ratio():\n",
    "        return bs.total_assets.latest / bs.common_stock_equity.latest\n",
    "\n",
    "    def Capex_To_Cashflows():\n",
    "        return (cfs.capital_expenditure.latest * 4.) / \\\n",
    "            (cfs.free_cash_flow.latest * 4.)\n",
    "        \n",
    "    def EBITDA_Yield():\n",
    "        return (is_.ebitda.latest * 4.) / \\\n",
    "            USEquityPricing.close.latest        \n",
    "\n",
    "    def EBIT_To_Assets():\n",
    "        return (is_.ebit.latest * 4.) / \\\n",
    "            bs.total_assets.latest\n",
    "        \n",
    "    def Earnings_Quality():\n",
    "        return morningstar.cash_flow_statement.operating_cash_flow.latest / \\\n",
    "               EarningsSurprises.eps_act.latest\n",
    "        \n",
    "    def Return_On_Total_Invest_Capital():\n",
    "        return or_.roic.latest\n",
    "    \n",
    "    class Mean_Reversion_1M(CustomFactor):\n",
    "        inputs = [Returns(window_length=21)]\n",
    "        window_length = 252\n",
    "\n",
    "        def compute(self, today, assets, out, monthly_rets):\n",
    "            out[:] = (monthly_rets[-1] - np.nanmean(monthly_rets, axis=0)) / \\\n",
    "                np.nanstd(monthly_rets, axis=0)\n",
    "                \n",
    "    class MACD_Signal_10d(CustomFactor):\n",
    "        inputs = [USEquityPricing.close]\n",
    "        window_length = 60\n",
    "\n",
    "        def compute(self, today, assets, out, close):\n",
    "\n",
    "            sig_lines = []\n",
    "\n",
    "            for col in close.T:\n",
    "                # get signal line only\n",
    "                try:\n",
    "                    _, signal_line, _ = talib.MACD(col, fastperiod=12,\n",
    "                                                   slowperiod=26, signalperiod=10)\n",
    "                    sig_lines.append(signal_line[-1])\n",
    "                # if error calculating, return NaN\n",
    "                except:\n",
    "                    sig_lines.append(np.nan)\n",
    "            out[:] = sig_lines \n",
    "            \n",
    "    class Moneyflow_Volume_5d(CustomFactor):\n",
    "        inputs = [USEquityPricing.close, USEquityPricing.volume]\n",
    "        window_length = 5\n",
    "\n",
    "        def compute(self, today, assets, out, close, volume):\n",
    "\n",
    "            mfvs = []\n",
    "\n",
    "            for col_c, col_v in zip(close.T, volume.T):\n",
    "\n",
    "                # denominator\n",
    "                denominator = np.dot(col_c, col_v)\n",
    "\n",
    "                # numerator\n",
    "                numerator = 0.\n",
    "                for n, price in enumerate(col_c.tolist()):\n",
    "                    if price > col_c[n - 1]:\n",
    "                        numerator += price * col_v[n]\n",
    "                    else:\n",
    "                        numerator -= price * col_v[n]\n",
    "\n",
    "                mfvs.append(numerator / denominator)\n",
    "            out[:] = mfvs  \n",
    "            \n",
    "           \n",
    "    def Net_Income_Margin():\n",
    "        return or_.net_margin.latest           \n",
    "\n",
    "    def Operating_Cashflows_To_Assets():\n",
    "        return (cfs.operating_cash_flow.latest * 4.) / \\\n",
    "            bs.total_assets.latest\n",
    "\n",
    "    def Price_Momentum_3M():\n",
    "        return Returns(window_length=63)\n",
    "    \n",
    "    class Price_Oscillator(CustomFactor):\n",
    "        inputs = [USEquityPricing.close]\n",
    "        window_length = 252\n",
    "\n",
    "        def compute(self, today, assets, out, close):\n",
    "            four_week_period = close[-20:]\n",
    "            out[:] = (np.nanmean(four_week_period, axis=0) /\n",
    "                      np.nanmean(close, axis=0)) - 1.\n",
    "    \n",
    "    def Returns_39W():\n",
    "        return Returns(window_length=215)\n",
    "    \n",
    "    class Trendline(CustomFactor):\n",
    "        inputs = [USEquityPricing.close]\n",
    "        window_length = 252\n",
    "\n",
    "        # using MLE for speed\n",
    "        def compute(self, today, assets, out, close):\n",
    "\n",
    "            # prepare X matrix (x_is - x_bar)\n",
    "            X = range(self.window_length)\n",
    "            X_bar = np.nanmean(X)\n",
    "            X_vector = X - X_bar\n",
    "            X_matrix = np.tile(X_vector, (len(close.T), 1)).T\n",
    "\n",
    "            # prepare Y matrix (y_is - y_bar)\n",
    "            Y_bar = np.nanmean(close, axis=0)\n",
    "            Y_bars = np.tile(Y_bar, (self.window_length, 1))\n",
    "            Y_matrix = close - Y_bars\n",
    "\n",
    "            # prepare variance of X\n",
    "            X_var = np.nanvar(X)\n",
    "\n",
    "            # multiply X matrix an Y matrix and sum (dot product)\n",
    "            # then divide by variance of X\n",
    "            # this gives the MLE of Beta\n",
    "            out[:] = (np.sum((X_matrix * Y_matrix), axis=0) / X_var) / \\\n",
    "                (self.window_length)\n",
    "        \n",
    "    class Vol_3M(CustomFactor):\n",
    "        inputs = [Returns(window_length=2)]\n",
    "        window_length = 63\n",
    "\n",
    "        def compute(self, today, assets, out, rets):\n",
    "            out[:] = np.nanstd(rets, axis=0)\n",
    "            \n",
    "    def Working_Capital_To_Assets():\n",
    "        return bs.working_capital.latest / bs.total_assets.latest   \n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "        \n",
    "    all_factors = {\n",
    "        'Asset Growth 3M': Asset_Growth_3M,\n",
    "        'Asset to Equity Ratio': Asset_To_Equity_Ratio,\n",
    "        'Capex to Cashflows': Capex_To_Cashflows,\n",
    "        'EBIT to Assets': EBIT_To_Assets,\n",
    "        'EBITDA Yield': EBITDA_Yield,        \n",
    "        'Earnings Quality': Earnings_Quality,\n",
    "        'MACD Signal Line': MACD_Signal_10d,\n",
    "        'Mean Reversion 1M': Mean_Reversion_1M,\n",
    "        'Moneyflow Volume 5D': Moneyflow_Volume_5d,\n",
    "        'Net Income Margin': Net_Income_Margin,        \n",
    "        'Operating Cashflows to Assets': Operating_Cashflows_To_Assets,\n",
    "        'Price Momentum 3M': Price_Momentum_3M,\n",
    "        'Price Oscillator': Price_Oscillator,\n",
    "        'Return on Invest Capital': Return_On_Total_Invest_Capital,\n",
    "        '39 Week Returns': Returns_39W,\n",
    "        'Trendline': Trendline,\n",
    "        'Vol 3M': Vol_3M,\n",
    "        'Working Capital to Assets': Working_Capital_To_Assets,   \n",
    "        \n",
    "    }        \n",
    "    \n",
    "    return all_factors\n",
    "factors = make_factors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "universe = Q1500US() # Define universe and select factors to use\n",
    "n_fwd_days = 5 # number of days to compute returns over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Momentum(CustomFactor):\n",
    "        \"\"\" Momentum factor \"\"\"\n",
    "        inputs = [USEquityPricing.close,\n",
    "                  Returns(window_length=126)]\n",
    "        window_length = 252\n",
    "\n",
    "        def compute(self, today, assets, out, prices, returns):\n",
    "            out[:] = ((prices[-21] - prices[-252])/prices[-252] - \\\n",
    "                      (prices[-1] - prices[-21])/prices[-21]) / np.nanstd(returns, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define and build the pipeline\n",
    "def make_history_pipeline(factors, universe, n_fwd_days=5):\n",
    "    # Call .rank() on all factors and mask out the universe\n",
    "    factor_zscore = {name: f().zscore(mask=universe) for name, f in factors.iteritems()}\n",
    "    # Get cumulative returns over last n_fwd_days days. We will later shift these.\n",
    "    factor_zscore['Returns'] = Returns(inputs=[USEquityPricing.open],\n",
    "                                      mask=universe, window_length=n_fwd_days)\n",
    "    factor_zscore['Momentum']=  Momentum(mask=universe)\n",
    "    factor_zscore['Sectors'] = Sector(mask=universe)\n",
    "    \n",
    "    \n",
    "    # Add many returns as factors\n",
    "    for i in [2,3,4,5,10,20]:\n",
    "        factor_zscore ['Return'+str(i)] = Returns(inputs=[USEquityPricing.open],\n",
    "                                      mask=universe, window_length=i)    \n",
    "    \n",
    "    #factor_zscore['SPY']=Returns(inputs=[USEquityPricing.open('SPY')] )\n",
    "    \n",
    "    pipe = Pipeline(screen=universe, columns=factor_zscore)\n",
    "    \n",
    "    return pipe\n",
    "history_pipe = make_history_pipeline(factors, universe, n_fwd_days=n_fwd_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because of problem with  time when taken a lot of data divide time to periods\n",
    "end_full = pd.Timestamp(\"2016-08-07\")\n",
    "period = pd.DateOffset(100)\n",
    "number_of_periods = 10\n",
    "results=pd.DataFrame()\n",
    "start = end_full-number_of_periods*(period)-(number_of_periods-1)*pd.DateOffset(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run pipeline\n",
    "start_timer = time()\n",
    "end_timer_loop = time()\n",
    "while end_full>start:\n",
    "    print 'start', start ,'end' ,start+period, end_timer_loop-start_timer\n",
    "    results_period = run_pipeline(history_pipe, start_date=start, end_date=start+period)\n",
    "    start+=(period+pd.DateOffset(1))\n",
    "    results_period.index.names = ['date', 'security']\n",
    "    results=pd.concat([results,results_period])\n",
    "    end_timer_loop=time()\n",
    "end_timer = time()\n",
    "print \"Time to run pipeline %.2f secs\" % (end_timer - start_timer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Work with sectors\n",
    "     -1: 'Misc',\n",
    "    101: 'Basic Materials',\n",
    "    102: 'Consumer Cyclical',\n",
    "    103: 'Financial Services',\n",
    "    104: 'Real Estate',\n",
    "    205: 'Consumer Defensive',\n",
    "    206: 'Healthcare',\n",
    "    207: 'Utilities',\n",
    "    308: 'Communication Services',\n",
    "    309: 'Energy',\n",
    "    310: 'Industrials',\n",
    "    311: 'Technology' ,    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_copy=results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results=results[results.Sectors==[101]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sometimes there are duplicated indexis\n",
    "results = results[~results.index.duplicated(keep='first')]\n",
    "# Massage data to be in the form expected by shift_mask_data()\n",
    "results_wo_returns = results.copy()\n",
    "returns = results_wo_returns.pop('Returns')\n",
    "Y = returns.unstack().values\n",
    "X = results_wo_returns.to_panel() \n",
    "X = X.swapaxes(2, 0).swapaxes(0, 1).values # (factors, time, stocks) -> (time, stocks, factors)\n",
    "results_wo_returns.index = results_wo_returns.index.set_levels(\n",
    "    results_wo_returns.index.get_level_values(1).map(lambda x: x.symbol), 1, )\n",
    "results_wo_returns.index = results_wo_returns.index.set_levels(\n",
    "    results_wo_returns.index.get_level_values(0).map(lambda x: x.date), 0, )\n",
    "\n",
    "# Train-test split\n",
    "train_size_perc = 0.8\n",
    "n_time, n_stocks, n_factors = X.shape\n",
    "train_size = np.int16(np.round(train_size_perc * n_time))\n",
    "X_train, Y_train = X[:train_size, ...], Y[:train_size]\n",
    "X_test, Y_test = X[(train_size+n_fwd_days):, ...], Y[(train_size+n_fwd_days):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_mask_data(X, Y, upper_percentile=60, lower_percentile=40, n_fwd_days=1):\n",
    "    # Shift X to match factors at t to returns at t+n_fwd_days (we want to predict future returns after all)\n",
    "    shifted_X = np.roll(X, n_fwd_days+1, axis=0)\n",
    "    \n",
    "    # Slice off rolled elements\n",
    "    X = shifted_X[n_fwd_days+1:]\n",
    "    Y = Y[n_fwd_days+1:]\n",
    "    \n",
    "    n_time, n_stocks, n_factors = X.shape\n",
    "    \n",
    "    # Look for biggest up and down movers\n",
    "    upper = np.nanpercentile(Y, upper_percentile, axis=1)[:, np.newaxis]\n",
    "    lower = np.nanpercentile(Y, lower_percentile, axis=1)[:, np.newaxis]\n",
    "  \n",
    "    upper_mask = (Y >= upper)\n",
    "    lower_mask = (Y <= lower)\n",
    "    \n",
    "    mask = upper_mask | lower_mask # This also drops nans\n",
    "    mask = mask.flatten()\n",
    "    \n",
    "    # Only try to predict whether a stock moved up/down relative to other stocks\n",
    "    Y_binary = np.zeros(n_time * n_stocks)\n",
    "    Y_binary[upper_mask.flatten()] = 0\n",
    "    Y_binary[lower_mask.flatten()] = 1\n",
    "    \n",
    "    # Flatten X\n",
    "    X = X.reshape((n_time * n_stocks, n_factors))\n",
    "\n",
    "    # Drop stocks that did not move much (i.e. are in the 30th to 70th percentile)\n",
    "    X = X[mask]\n",
    "    Y_binary = Y_binary[mask]\n",
    "    \n",
    "    return X, Y_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_shift, Y_train_shift = shift_mask_data(X_train, Y_train, n_fwd_days=n_fwd_days, \n",
    "                                             lower_percentile=30,\n",
    "                                             upper_percentile=70)\n",
    "X_test_shift, Y_test_shift = shift_mask_data(X_test, Y_test, n_fwd_days=n_fwd_days, \n",
    "                                             lower_percentile=50, \n",
    "                                             upper_percentile=50)\n",
    "\n",
    "print X_train_shift.shape, X_test_shift.shape\n",
    "print Y_train_shift.shape, Y_test_shift.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = preprocessing.Imputer()\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "X_train_trans = imputer.fit_transform(X_train_shift)\n",
    "X_train_trans = scaler.fit_transform(X_train_trans)\n",
    "X_test_trans = imputer.transform(X_test_shift)\n",
    "X_test_trans = scaler.transform(X_test_trans)\n",
    "print X_train_trans.shape, X_test_trans.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_metrics = {\n",
    "            'accuracy': metrics.accuracy_score,\n",
    "            'precision':metrics.precision_score,\n",
    "            'recall': metrics.recall_score ,\n",
    "            'f1':metrics.f1_score,  \n",
    "                }\n",
    "metric_colors = {\n",
    "            'accuracy': 'r',\n",
    "             'precision':'b',\n",
    "            'recall': 'g' ,\n",
    "            'f1':'orange',\n",
    "            'time':'blue',\n",
    "            'time_PCA':'black'\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#work with all results and all PCA components\n",
    "\n",
    "clf = ensemble.RandomForestClassifier(max_depth=40,n_estimators=100) \n",
    "metric_results_PCA={}\n",
    "for metric in cls_metrics:\n",
    "    metric_results_PCA.update({metric:[]});\n",
    "    metric_results_PCA.update({'time':[]});\n",
    "    metric_results_PCA.update({'time_PCA':[]});\n",
    "    \n",
    "    \n",
    "pca_numbers = np.array(range(1,X_train_trans.shape[1]+1))  \n",
    "\n",
    "\n",
    "for pca_number in pca_numbers :\n",
    "    print pca_number,\n",
    "    pca=decomposition.PCA(n_components = pca_number)\n",
    "    start_timer_PCA=time()\n",
    "    X_train_trans_PCA = pca.fit_transform(X_train_trans)\n",
    "    X_test_trans_PCA = pca.transform(X_test_trans)\n",
    "    end_timer_PCA=time()\n",
    "    \n",
    "    start_timer=time()\n",
    "    clf.fit(X_train_trans_PCA, Y_train_shift)\n",
    "    Y_pred_test_PCA    = clf.predict(X_test_trans_PCA)\n",
    "    end_timer=time()\n",
    "\n",
    "    \n",
    "    for metric in cls_metrics:         \n",
    "        temp = cls_metrics[metric](Y_test_shift, Y_pred_test_PCA)\n",
    "        metric_results_PCA[metric].append(temp)\n",
    "    \n",
    "    metric_results_PCA['time'].append(end_timer-start_timer)\n",
    "    metric_results_PCA['time_PCA'].append(end_timer_PCA-start_timer_PCA)\n",
    "\n",
    "\n",
    "clf.fit(X_train_trans, Y_train_shift)\n",
    "Y_pred_test = clf.predict(X_test_trans)\n",
    "\n",
    "for metric in cls_metrics:         \n",
    "    temp = cls_metrics[metric](Y_test_shift, Y_pred_test)\n",
    "    metric_results_PCA[metric].append(temp)\n",
    "    \n",
    "   \n",
    "\n",
    "\n",
    "mywidth =0.1  \n",
    "shift=-(len(cls_metrics)-1)/2*mywidth\n",
    "pca_numbers_rf = np.array(range(1,X_train_trans.shape[1]+2))  \n",
    "for metric in cls_metrics:\n",
    "        \n",
    "    plt.bar(pca_numbers_rf+shift, metric_results_PCA[metric], width=mywidth,\n",
    "        label = metric, color=metric_colors[metric])\n",
    "    shift += mywidth\n",
    "   \n",
    "\n",
    "plt.title(\"Comparing numbers of components in PCA\")\n",
    "plt.xlabel('Numbers of components')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "\n",
    "plt.ylim((0.,1))\n",
    "plt.xlim((0,27))\n",
    "plt.show()\n",
    "\n",
    "plt.bar(np.array(range(1,len(pca_numbers)+1))-mywidth, metric_results_PCA['time'], width=mywidth,\n",
    "        label = 'time to train RF', color='r')\n",
    "plt.bar(np.array(range(1,len(pca_numbers)+1)), metric_results_PCA['time_PCA'], width=mywidth,\n",
    "        label = 'time to train PCA', color='orange')\n",
    "\n",
    "plt.title(\"Time to train\")\n",
    "plt.xlabel('Number of components')\n",
    "plt.xticks(np.array(range(1,len(pca_numbers)+1)), pca_numbers, rotation='vertical')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "\n",
    "plt.xlim((0,27))\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "for metric in cls_metrics:\n",
    "     print metric, ' & ',max(metric_results_PCA[metric]), ' & ', pca_numbers[np.argmax(metric_results_PCA[metric])] , \\\n",
    "    \"\\\\ \\hline\"\n",
    "   \n",
    "     print metric, ' & ', metric_results_PCA[metric][-1],' & ', 'without PCA' , \\\n",
    "    \"\\\\ \\hline\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for rs in range(1,50) :\n",
    "    print 'random state', rs\n",
    "    sectors=[308]\n",
    "    clf = ensemble.RandomForestClassifier(max_depth=40,n_estimators=40,random_state=rs) \n",
    "\n",
    "\n",
    "    for sector in sectors:\n",
    "        print 'Sector', sector\n",
    "        results=results_copy[results_copy.Sectors==[sector]]\n",
    "\n",
    "            # Sometimes there are duplicated indexis\n",
    "        results = results[~results.index.duplicated(keep='first')]\n",
    "        # Massage data to be in the form expected by shift_mask_data()\n",
    "        results_wo_returns = results.copy()\n",
    "        returns = results_wo_returns.pop('Returns')\n",
    "        Y = returns.unstack().values\n",
    "        X = results_wo_returns.to_panel() \n",
    "        X = X.swapaxes(2, 0).swapaxes(0, 1).values # (factors, time, stocks) -> (time, stocks, factors)\n",
    "        results_wo_returns.index = results_wo_returns.index.set_levels(\n",
    "            results_wo_returns.index.get_level_values(1).map(lambda x: x.symbol), 1, )\n",
    "        results_wo_returns.index = results_wo_returns.index.set_levels(\n",
    "            results_wo_returns.index.get_level_values(0).map(lambda x: x.date), 0, )\n",
    "\n",
    "        # Train-test split\n",
    "        train_size_perc = 0.8\n",
    "        n_time, n_stocks, n_factors = X.shape\n",
    "        train_size = np.int16(np.round(train_size_perc * n_time))\n",
    "        X_train, Y_train = X[:train_size, ...], Y[:train_size]\n",
    "        X_test, Y_test = X[(train_size+n_fwd_days):, ...], Y[(train_size+n_fwd_days):]\n",
    "\n",
    "        X_train_shift, Y_train_shift = shift_mask_data(X_train, Y_train, n_fwd_days=n_fwd_days, \n",
    "                                                     lower_percentile=30,\n",
    "                                                     upper_percentile=70)\n",
    "        X_test_shift, Y_test_shift = shift_mask_data(X_test, Y_test, n_fwd_days=n_fwd_days, \n",
    "                                                     lower_percentile=50, \n",
    "                                                     upper_percentile=50)\n",
    "\n",
    "\n",
    "        imputer = preprocessing.Imputer()\n",
    "        scaler = preprocessing.MinMaxScaler()\n",
    "        X_train_trans = imputer.fit_transform(X_train_shift)\n",
    "        X_train_trans = scaler.fit_transform(X_train_trans)\n",
    "        X_test_trans = imputer.transform(X_test_shift)\n",
    "        X_test_trans = scaler.transform(X_test_trans)\n",
    "\n",
    "        metric_results_PCA={}\n",
    "        for metric in cls_metrics:\n",
    "            metric_results_PCA.update({metric:[]});\n",
    "            metric_results_PCA.update({'time':[]});\n",
    "            metric_results_PCA.update({'time_PCA':[]});\n",
    "\n",
    "\n",
    "        pca_numbers = np.array(range(1,X_train_trans.shape[1]+1))  \n",
    "\n",
    "\n",
    "        for pca_number in pca_numbers :\n",
    "            print pca_number,\n",
    "            pca=decomposition.PCA(n_components = pca_number)\n",
    "            start_timer_PCA=time()\n",
    "            X_train_trans_PCA = pca.fit_transform(X_train_trans)\n",
    "            X_test_trans_PCA = pca.transform(X_test_trans)\n",
    "            end_timer_PCA=time()\n",
    "\n",
    "            start_timer=time()\n",
    "            clf.fit(X_train_trans_PCA, Y_train_shift)\n",
    "            Y_pred_test_PCA    = clf.predict(X_test_trans_PCA)\n",
    "            end_timer=time()\n",
    "\n",
    "\n",
    "            for metric in cls_metrics:         \n",
    "                temp = cls_metrics[metric](Y_test_shift, Y_pred_test_PCA)\n",
    "                metric_results_PCA[metric].append(temp)\n",
    "\n",
    "            metric_results_PCA['time'].append(end_timer-start_timer)\n",
    "            metric_results_PCA['time_PCA'].append(end_timer_PCA-start_timer_PCA)\n",
    "\n",
    "\n",
    "        clf.fit(X_train_trans, Y_train_shift)\n",
    "        Y_pred_test = clf.predict(X_test_trans)\n",
    "\n",
    "        for metric in cls_metrics:         \n",
    "            temp = cls_metrics[metric](Y_test_shift, Y_pred_test)\n",
    "            metric_results_PCA[metric].append(temp)\n",
    "\n",
    "        mywidth =0.1  \n",
    "        shift=-(len(cls_metrics)-1)/2*mywidth\n",
    "        pca_numbers_rf = np.array(range(1,X_train_trans.shape[1]+2))  \n",
    "        for metric in cls_metrics:\n",
    "\n",
    "            plt.bar(pca_numbers_rf+shift, metric_results_PCA[metric], width=mywidth,\n",
    "                label = metric, color=metric_colors[metric])\n",
    "            shift += mywidth\n",
    "\n",
    "\n",
    "        plt.title(\"Comparing numbers of components in PCA\")\n",
    "        plt.xlabel('Numbers of components')\n",
    "        plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "\n",
    "        plt.ylim((0.,1))\n",
    "        plt.xlim((0,27))\n",
    "        plt.show()\n",
    "\n",
    "        print metrics.confusion_matrix(Y_test_shift, Y_pred_test)\n",
    "\n",
    "\n",
    "\n",
    "        for metric in cls_metrics:\n",
    "             print metric, ' & ',max(metric_results_PCA[metric]), ' & ', pca_numbers[np.argmax(metric_results_PCA[metric])-1] , \\\n",
    "            \"\\\\ \\hline\"\n",
    "\n",
    "             print metric, ' & ', metric_results_PCA[metric][-1],' & ', 'without PCA' , \\\n",
    "            \"\\\\ \\hline\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                                                                                                                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sectors=[101,102,103,104,205,206,207,308,309,310,311]\n",
    "\n",
    "metric_results_Sectors={}\n",
    "for metric in cls_metrics:\n",
    "    metric_results_Sectors.update({metric:[]});\n",
    "\n",
    "metric_results_Sectors_PCA={}\n",
    "for metric in cls_metrics:\n",
    "    metric_results_Sectors_PCA.update({metric:[]});\n",
    "    \n",
    "pca_number=9\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sector in sectors:\n",
    "    results=results_copy[results_copy.Sectors==[sector]]\n",
    "    # Sometimes there are duplicated indexis\n",
    "    results = results[~results.index.duplicated(keep='first')]\n",
    "    # Massage data to be in the form expected by shift_mask_data()\n",
    "    results_wo_returns = results.copy()\n",
    "    returns = results_wo_returns.pop('Returns')\n",
    "    Y = returns.unstack().values\n",
    "    X = results_wo_returns.to_panel() \n",
    "    X = X.swapaxes(2, 0).swapaxes(0, 1).values # (factors, time, stocks) -> (time, stocks, factors)\n",
    "    results_wo_returns.index = results_wo_returns.index.set_levels(\n",
    "        results_wo_returns.index.get_level_values(1).map(lambda x: x.symbol), 1, )\n",
    "    results_wo_returns.index = results_wo_returns.index.set_levels(\n",
    "        results_wo_returns.index.get_level_values(0).map(lambda x: x.date), 0, )\n",
    "\n",
    "    # Train-test split\n",
    "    train_size_perc = 0.8\n",
    "    n_time, n_stocks, n_factors = X.shape\n",
    "    train_size = np.int16(np.round(train_size_perc * n_time))\n",
    "    X_train, Y_train = X[:train_size, ...], Y[:train_size]\n",
    "    X_test, Y_test = X[(train_size+n_fwd_days):, ...], Y[(train_size+n_fwd_days):]\n",
    "    X_train_shift, Y_train_shift = shift_mask_data(X_train, Y_train, n_fwd_days=n_fwd_days, \n",
    "                                                 lower_percentile=30,\n",
    "                                                 upper_percentile=70)\n",
    "    X_test_shift, Y_test_shift = shift_mask_data(X_test, Y_test, n_fwd_days=n_fwd_days, \n",
    "                                                 lower_percentile=50, \n",
    "                                                 upper_percentile=50)\n",
    "\n",
    "    imputer = preprocessing.Imputer()\n",
    "    scaler = preprocessing.MinMaxScaler()\n",
    "    X_train_trans = imputer.fit_transform(X_train_shift)\n",
    "    X_train_trans = scaler.fit_transform(X_train_trans)\n",
    "    X_test_trans = imputer.transform(X_test_shift)\n",
    "    X_test_trans = scaler.transform(X_test_trans)\n",
    "\n",
    "\n",
    "    pca=decomposition.PCA(n_components = pca_number)\n",
    "    X_train_trans_PCA = pca.fit_transform(X_train_trans)\n",
    "    X_test_trans_PCA = pca.transform(X_test_trans)\n",
    "    clf.fit(X_train_trans_PCA, Y_train_shift)\n",
    "    Y_pred_test_PCA    = clf.predict(X_test_trans_PCA)\n",
    "\n",
    "    for metric in cls_metrics:         \n",
    "        temp = cls_metrics[metric](Y_test_shift, Y_pred_test_PCA)\n",
    "        metric_results_Sectors_PCA[metric].append(temp)\n",
    "\n",
    "    clf.fit(X_train_trans, Y_train_shift)\n",
    "    Y_pred_test = clf.predict(X_test_trans)\n",
    "\n",
    "    for metric in cls_metrics:         \n",
    "        temp = cls_metrics[metric](Y_test_shift, Y_pred_test)\n",
    "        metric_results_Sectors[metric].append(temp)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mywidth =0.1  \n",
    "shift=-(len(cls_metrics))*mywidth\n",
    "\n",
    "for metric in cls_metrics:     \n",
    "    plt.bar(np.array(range(1,len(sectors)+1))+shift, metric_results_Sectors[metric], width=mywidth,\\\n",
    "            label = metric, color=metric_colors[metric])\n",
    "    shift += 2*mywidth\n",
    "\n",
    "shift=-(len(cls_metrics))*mywidth+mywidth \n",
    "\n",
    "for metric in cls_metrics:     \n",
    "    plt.bar(np.array(range(1,len(sectors)+1))+shift, metric_results_Sectors_PCA[metric], width=mywidth,\\\n",
    "            label = metric, color=metric_colors[metric])\n",
    "    shift += 2*mywidth\n",
    "    \n",
    "    \n",
    "    \n",
    "plt.title(\"Metrics for different sectors\")\n",
    "plt.xlabel('Sectors')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.xticks(np.array(range(1,len(sectors)+1)), sectors, rotation='vertical')\n",
    "plt.ylim((0,1))\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_results_RF={}\n",
    "for metric in cls_metrics:\n",
    "    metric_results_RF.update({metric:[]})\n",
    "    metric_results_RF.update({'time':[]})\n",
    "    metric_results_RF.update({'depth':[]})\n",
    "    metric_results_RF.update({'estimator':[]})\n",
    "    metric_results_RF.update({'feature':[]})\n",
    "    \n",
    "depths =  np.array([40,100])\n",
    "features =  np.array([3,4,5,6])\n",
    "estimators =  np.array([10,40])\n",
    "\n",
    "\n",
    "for depth in depths:\n",
    "    for feature in features:\n",
    "        for estimator in estimators:  \n",
    "            start_timer = time()\n",
    "            #clf = ensemble.RandomForestClassifier(max_depth=depth,n_estimators=estimator,max_features= feature) \n",
    "            clf= ensemble.AdaBoostClassifier(n_estimators=estimator)\n",
    "            clf.fit(X_train_trans, Y_train_shift)\n",
    "            Y_pred_test = clf.predict(X_test_trans)\n",
    "            end_timer = time()\n",
    "            print 'depth',depth, 'feat', feature, 'est', estimator , \\\n",
    "            cls_metrics['precision'](Y_test_shift, Y_pred_test), end_timer-start_timer\n",
    "\n",
    "            for metric in cls_metrics:         \n",
    "                temp = cls_metrics[metric](Y_test_shift, Y_pred_test)\n",
    "                metric_results_RF[metric].append(temp)\n",
    "\n",
    "            metric_results_RF['time'].append(end_timer-start_timer)\n",
    "            metric_results_RF['depth'].append(depth)\n",
    "            metric_results_RF['estimator'].append(estimator)\n",
    "            metric_results_RF['feature'].append(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for metric in cls_metrics:\n",
    "    print 'max', metric, 'max value', max(metric_results_RF[metric]), 'for ' ,\\\n",
    "    'depth', metric_results_RF['depth'][np.argmax(metric_results_RF[metric])],\\\n",
    "    'estimator', metric_results_RF['estimator'][np.argmax(metric_results_RF[metric])],\\\n",
    "    'feature', metric_results_RF['feature'][np.argmax(metric_results_RF[metric])]\n",
    "    \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_results_RF={}\n",
    "for metric in cls_metrics:\n",
    "    metric_results_RF.update({metric:[]})\n",
    "    metric_results_RF.update({'time':[]});\n",
    "depths =  np.array([1,2,3,5,6,7,15,10,40,50,100,200,300,500])\n",
    "    \n",
    "for depth in depths:\n",
    "    start_timer = time()\n",
    "    clf = ensemble.RandomForestClassifier(max_depth=depth,n_estimators=100) \n",
    "    clf.fit(X_train_trans, Y_train_shift)\n",
    "    \n",
    "    Y_pred_test = clf.predict(X_test_trans)\n",
    "    end_timer = time()\n",
    "    print depth,\n",
    "    \n",
    "    for metric in cls_metrics:         \n",
    "        temp = cls_metrics[metric](Y_test_shift, Y_pred_test)\n",
    "        metric_results_RF[metric].append(temp)\n",
    "    \n",
    "    metric_results_RF['time'].append(end_timer-start_timer)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mywidth = 0.1\n",
    "shift = -(len(cls_metrics)-1)/2*mywidth\n",
    "\n",
    "for metric in cls_metrics:\n",
    "       \n",
    "    plt.bar(np.array(range(1,len(depths)+1))+shift, metric_results_RF[metric], width=mywidth,\n",
    "        label = metric, color=metric_colors[metric])\n",
    "    shift += mywidth\n",
    "   \n",
    "plt.title(\"Comparing depth\")\n",
    "plt.xlabel('Maximum depth')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.xticks(np.array(range(1,len(depths)+1)), depths, rotation='vertical')\n",
    "plt.ylim((0.45,0.62))\n",
    "plt.show()    \n",
    "\n",
    "plt.bar(np.array(range(1,len(depths)+1)), metric_results_RF['time'], width=mywidth,\n",
    "        label = 'time', color=metric_colors[metric])\n",
    "plt.title(\"Time to train\")\n",
    "plt.xlabel('Maximum depth')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.xticks(np.array(range(1,len(depths)+1)), depths, rotation='vertical')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "for metric in cls_metrics:\n",
    "    print metric, 'for depth', depths[np.argmax(metric_results_RF[metric])] \\\n",
    "    ,'max value', max(metric_results_RF[metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_results_RF={}\n",
    "for metric in cls_metrics:\n",
    "    metric_results_RF.update({metric:[]})\n",
    "    metric_results_RF.update({'time':[]});\n",
    "    \n",
    "estimators =  np.array([10,20,30,35,40,45,50,70,100,200,300,400,500,])\n",
    "    \n",
    "for estimator in estimators:\n",
    "    start_timer = time()\n",
    "    clf = ensemble.RandomForestClassifier(max_depth=30,n_estimators=estimator) \n",
    "    clf.fit(X_train_trans, Y_train_shift)\n",
    "    \n",
    "    Y_pred_test = clf.predict(X_test_trans)\n",
    "    end_timer = time()\n",
    "    print estimator,\n",
    "    \n",
    "    for metric in cls_metrics:         \n",
    "        temp = cls_metrics[metric](Y_test_shift, Y_pred_test)\n",
    "        metric_results_RF[metric].append(temp)\n",
    "    \n",
    "    metric_results_RF['time'].append(end_timer-start_timer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mywidth = 0.1\n",
    "shift = -(len(cls_metrics)-1)/2*mywidth\n",
    "\n",
    "for metric in cls_metrics:\n",
    "       \n",
    "    plt.bar(np.array(range(1,len(estimators)+1))+shift, metric_results_RF[metric], width=mywidth,\n",
    "        label = metric, color=metric_colors[metric])\n",
    "    shift += mywidth\n",
    "   \n",
    "plt.title(\"Comparing number of estimators\")\n",
    "plt.xlabel('Number of estimators')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.xticks(np.array(range(1,len(estimators)+1)), estimators, rotation='vertical')\n",
    "plt.ylim((0.4,0.55))\n",
    "plt.show()    \n",
    "\n",
    "plt.bar(np.array(range(1,len(estimators)+1)), metric_results_RF['time'], width=mywidth,\n",
    "        label = 'time', color=metric_colors[metric])\n",
    "plt.title(\"Time to train\")\n",
    "plt.xlabel('Number of estimators')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.xticks(np.array(range(1,len(estimators)+1)), estimators, rotation='vertical')\n",
    "plt.show()\n",
    "\n",
    "for metric in cls_metrics:\n",
    "    print 'max', metric, 'for variable', estimators[np.argmax(metric_results_RF[metric])] \\\n",
    "    ,'max value', max(metric_results_RF[metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_results_RF={}\n",
    "for metric in cls_metrics:\n",
    "    metric_results_RF.update({metric:[]})\n",
    "    metric_results_RF.update({'time':[]});\n",
    "    \n",
    "changed_variables =  np.array([1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18])\n",
    "    \n",
    "for changed_variable in changed_variables:\n",
    "    start_timer = time()\n",
    "    clf = ensemble.RandomForestClassifier(max_depth=30,n_estimators=30,max_features= changed_variable) \n",
    "    clf.fit(X_train_trans, Y_train_shift)\n",
    "    \n",
    "    Y_pred_test = clf.predict(X_test_trans)\n",
    "    end_timer = time()\n",
    "    print changed_variable,\n",
    "    \n",
    "    for metric in cls_metrics:         \n",
    "        temp = cls_metrics[metric](Y_test_shift, Y_pred_test)\n",
    "        metric_results_RF[metric].append(temp)\n",
    "    \n",
    "    metric_results_RF['time'].append(end_timer-start_timer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mywidth = 0.1\n",
    "shift = -(len(cls_metrics)-1)/2*mywidth\n",
    "\n",
    "for metric in cls_metrics:\n",
    "       \n",
    "    plt.bar(np.array(range(1,len(changed_variables)+1))+shift, metric_results_RF[metric], width=mywidth,\n",
    "        label = metric, color=metric_colors[metric])\n",
    "    shift += mywidth\n",
    "   \n",
    "plt.title(\"Comparing max features\")\n",
    "plt.xlabel('Maximum features')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.xticks(np.array(range(1,len(changed_variables)+1)), changed_variables, rotation='vertical')\n",
    "plt.ylim((0.45,0.6))\n",
    "plt.show()    \n",
    "\n",
    "plt.bar(np.array(range(1,len(changed_variables)+1)), metric_results_RF['time'], width=mywidth,\n",
    "        label = 'time', color=metric_colors[metric])\n",
    "plt.title(\"Time to train\")\n",
    "plt.xlabel('Maximum feauters')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.xticks(np.array(range(1,len(changed_variables)+1)), changed_variables, rotation='vertical')\n",
    "plt.show()\n",
    "\n",
    "for metric in cls_metrics:\n",
    "    print 'max', metric, 'for max features', changed_variables[np.argmax(metric_results_RF[metric])] \\\n",
    "    ,'max value', max(metric_results_RF[metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
